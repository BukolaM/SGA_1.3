# Stutern
Stutern projects introduce one to data science to help understand what it is, the steps and processes involved, and the tools and techniques used to collect, wrangle, analyze, and extract insights from a given data set.


### Data Science Methodology
The OSEMN framework is comprised of five major steps and can be summarized as follows:
#### 1. Obtain Information (Data Collection):
Data is required for the data science process and can come from pre-existing or newly acquired ones (from surveys), newly queried data (from databases or APIs), downloaded from the internet (e.g. from cloud repositories such as GitHub), or extracted.
This could entail determining exactly what data is required and the best methods for obtaining it. This also entails determining what each of the data points means in terms of the company.
#### 2. Data Scrub (Data Preparation):
Scrubbing the data is essentially data cleaning, and this phase is considered to be the most time-consuming as it involves handling missing data as well as preprocessing it to be as error-free and uniform as possible.
#### 3. Investigate Data (Data Exploration):
This is essentially exploratory data analysis, and this phase allows us to gain an understanding of the data such that we can figure out the course of action and areas that we can explore in the modeling phase. This entails the use of descriptive statistics and data visualizations.
#### 4. Data Modeling (Model Data):
Here, we make use of machine learning algorithms in an effort to make sense of data and gain useful insights that are essential for data-driven decision-making.
You may have to try on a few different models before finding the one thatâ€™s right for you. Going back to how the data was prepared may be necessary to accomplish this.
#### 5. Interpret the Findings (Data Interpretation):
This is perhaps one of the most important phases and yet the least technical as it pertains to actually making sense of the data by figuring out how to simplify and summarize results from all the models built. This entails drawing meaningful conclusions and rationalizing actionable insights that would essentially allow us to figure out what the next course of action is.
This is also the stage in which you verify that the model answers the business questions or problems you posed at the start of the process. It may lead to the discovery of new, more important questions.
It should be noted that the data science flow is not linear and that, in practice, the flow can be non-linear and can re-iterate until a satisfactory condition is met.


## Fundamental Tools Used in These Projects
- Python
- SQL
- Matplotlib
- Numpy
- Pandas